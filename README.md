# Manual_QA_Project_1 ‚Äî Manual Testing Portfolio (SauceDemo)

This repository showcases an end‚Äëto‚Äëend **manual QA project** on the public demo site **SauceDemo (Swag Labs)**. It is designed to demonstrate my test planning, scenario design, traceability, execution discipline, and defect reporting skills.

> **What‚Äôs inside:** A complete, set of QA artifacts ‚Äî **Test Plan**, **Test Scenarios**, **RTM**, **Detailed Test Cases**, **Test Execution Results**, and a **Bug Report** ‚Äî all linked and consistent.

---

## üìå Project Objectives

* Validate the core shopper journey: **login ‚Üí browse/sort ‚Üí cart ‚Üí checkout**.
* Demonstrate **risk‚Äëbased** and **user‚Äëjourney‚Äëfocused** test strategy with forward/backward **traceability**.
* Test the behaviour of all kinds of user accounts - **standard_user**, **locked_out_user**, **problem_use**r, **performance_glitch_user**, **error_user**, **visual_user**
* Produce clean, auditable artifacts suitable for a QA portfolio and real‚Äëworld processes.

---

## üîó Repository Structure

* **[1_Test_Plan_Sauce_Demo.pdf](https://github.com/Showrav-Dhar/Manual_QA_Project_1/blob/main/1_Test_Plan_Sauce_Demo.pdf)** ‚Äî overall scope, strategy, risks, environments, entry/exit criteria, and schedule.
* **[2_Test_Scenarios_Sauce_Demo.xlsx](https://github.com/Showrav-Dhar/Manual_QA_Project_1/blob/main/2_Test_Scenarios_Sauce_Demo.xlsx)** ‚Äî prioritized, high‚Äëlevel scenarios with requirement IDs.
* **[3_RTM_Sauce_Demo.xlsx](https://github.com/Showrav-Dhar/Manual_QA_Project_1/blob/main/3_RTM_Sauce_Demo.xlsx)** ‚Äî Requirement ‚áÑ Scenario ‚áÑ (Test Case) mapping for full coverage.
* **[4_Test_Cases_Sauce_Demo.xlsx](https://github.com/Showrav-Dhar/Manual_QA_Project_1/blob/main/4_Test_Cases_Sauce_Demo.xlsx)** ‚Äî step‚Äëby‚Äëstep test cases (with data & expected results).
* **[5_Test_Execution_Result_Sauce_Demo.xlsx](https://github.com/Showrav-Dhar/Manual_QA_Project_1/blob/main/5_Test_Execution_Result_Sauce_Demo.xlsx)** ‚Äî execution log (Smoke + Functional/Regression), results, evidence links.
* **[6_Bug_Report_Sauce_Demo.xlsx](https://github.com/Showrav-Dhar/Manual_QA_Project_1/blob/main/6_Bug_Report_Sauce_Demo.xlsx)** ‚Äî concise defect log (summary, steps, expected vs actual, severity/priority, screenshot).

> File names are prefixed numerically to reflect the real workflow order from **plan ‚Üí design ‚Üí trace ‚Üí execute ‚Üí report**.

---

## üß≠ Scope (In/Out)

**In scope:**

* **Authentication:** positive login, negative (invalid/locked out), logout.
* **Catalog:** inventory loads, sort (A‚ÜíZ, Z‚ÜíA, price low‚Üíhigh, high‚Üílow), product details.
* **Cart:** add/remove items, badge count, state persistence.
* **Checkout:** data validation, overview accuracy, finish flow.
* **Basic UX:** labels, error clarity, menu/footer/social links (smoke level).

**Out of scope:** Full performance, security, and accessibility audits; mobile device matrix; back‚Äëoffice/admin modules; real payment/email flows.

---

## üß™ Test Strategy Highlights

* **Approach:** Risk‚Äëbased, user‚Äëjourney first; **shift‚Äëleft** clarity (scenarios before cases); evidence‚Äëdriven.
* **Levels:** Smoke ‚Üí Functional; plus short **exploratory** passes.
* **Design techniques:** Equivalence classes, boundary values (checkout form), decision tables (auth), state transitions (cart add/remove).
* **Prioritization:** P0 (happy path blockers), P1 (core variants), P2 (peripheral/edges).
* **Traceability:** RTM links **Requirements ‚Üí Scenarios ‚Üí Test Cases ‚Üí Results/Defects**.
---

## üß© How to Read the Artifacts

1. **Start with the Test Plan** to understand scope, risks, and environment.
2. **Open Test Scenarios** to see the high‚Äëlevel journeys (TS‚ÄëIDs) tied to **REQ‚ÄëIDs**.
3. **Check the RTM** to confirm coverage from requirements down to execution.
4. **Review Test Cases** (TC‚ÄëIDs) for reproducible steps and expected results.
5. **Inspect Execution Results** to see pass/fail, evidence links, and timing.
6. **Look at the Bug Report** to evaluate defect quality (clear titles, steps, expected vs actual, severity/priority, screenshots).

---

## üêõ Defect Logging (examples)

Each bug entry includes: **Summary**, **Steps to Reproduce**, **Expected vs Actual**, **Severity (S1‚ÄìS4)**, **Priority (P0‚ÄìP2)**, and **Screenshot** link.

> See **6_Bug_Report_Sauce_Demo.xlsx** for full details and evidence.

---

## üõ†Ô∏è Tools & Environment

* **Authoring/Reporting:** Excel, PDF, screenshots.
* **Browsers:** Chrome (latest), Firefox (latest) on desktop.
* **AUT:** SauceDemo (public demo). No real payments/email required.

---

## üéØ Skills Demonstrated

* Test planning & risk management
* Scenario derivation & traceability (**RTM**)
* Detailed test case design (clear oracles, repeatability)
* Evidence‚Äëbased execution & concise status reporting
* Defect reporting with actionable steps and prioritization
  
---

## üì£ Why this project?

This repo mirrors a realistic QA workflow while keeping scope focused. It demonstrates how one would structure manual testing in a new team: start from a crisp **Test Plan**, drive **traceable** design, capture **evidence**, report **actionable defects**, and **communicate status** clearly.

-- 

## Short Summary

* **Standard_user** - Every functionality works as expected.
* **Locked_out_user** - Can not log in.
* **Problem_user** - Most of the functionality is not working as expected like product display, checkout, product details etc.
* **Performance_glitch_user**  - Login working but every other functionality is responding very slowly.
* **Error_user** - Images are not displaying correctly and also other bugs are present.
* **Visual_user** - Most of the bugs are UI related, icons are not showing properly, Icon/Logo aligning problem etc.
